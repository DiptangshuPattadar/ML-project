{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiptangshuPattadar/ML-project/blob/main/ANOMALY_DETECTION_IN_NETWORK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Network Anomaly Detection System\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                           confusion_matrix, roc_curve, auc)\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Set modern visualization style\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "def plot_class_distribution(y, title, filename):\n",
        "    plt.figure()\n",
        "    sns.countplot(x=y)\n",
        "    plt.title(f'Class Distribution: {title}')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Count')\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_clusters(X, clusters, filename):\n",
        "    plt.figure()\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters, palette=\"viridis\")\n",
        "    plt.title('Cluster Visualization (PCA)')\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_anomaly_scores(scores, y_true, filename):\n",
        "    plt.figure()\n",
        "    sns.kdeplot(scores[y_true==0], label='Normal', fill=True)\n",
        "    sns.kdeplot(scores[y_true==1], label='Anomaly', fill=True)\n",
        "    plt.title('Anomaly Score Distribution')\n",
        "    plt.xlabel('Anomaly Score')\n",
        "    plt.legend()\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_feature_importance(model, feature_names, top_n=20, filename='feature_importance.png'):\n",
        "    plt.figure()\n",
        "    importances = model.feature_importances_\n",
        "    indices = np.argsort(importances)[-top_n:]\n",
        "    plt.title(f'Top {top_n} Feature Importance')\n",
        "    plt.barh(range(top_n), importances[indices], align='center')\n",
        "    plt.yticks(range(top_n), [feature_names[i] for i in indices])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, filename):\n",
        "    plt.figure()\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_roc_curve(y_true, y_proba, filename):\n",
        "    plt.figure()\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Load and preprocess data\n",
        "train_df = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
        "test_df = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "# Clean and prepare data\n",
        "train_df = train_df.dropna(subset=['label'])\n",
        "test_df = test_df.dropna(subset=['label'])\n",
        "\n",
        "# Label Encoding with alignment\n",
        "label_encoders = {}\n",
        "for col in train_df.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(pd.concat([train_df[col], test_df[col]]).astype(str))\n",
        "    train_df[col] = le.transform(train_df[col].astype(str))\n",
        "    test_df[col] = le.transform(test_df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Feature engineering with safe operations\n",
        "def create_features(df):\n",
        "    eps = 1e-9\n",
        "    df = df.copy()\n",
        "    return df.assign(\n",
        "        sbytes_dbytes_ratio = np.divide(df['sbytes'], df['dbytes'] + eps),\n",
        "        sttl_dttl_ratio = np.divide(df['sttl'], df['dttl'] + eps),\n",
        "        sload_dload_ratio = np.divide(df['sload'], df['dload'] + eps),\n",
        "        spkts_dpkts_ratio = np.divide(df['spkts'], df['dpkts'] + eps)\n",
        "    ).fillna(0).replace([np.inf, -np.inf], 0)\n",
        "\n",
        "# Create and align features\n",
        "X_train = create_features(train_df.drop(columns=['label']))\n",
        "X_test = create_features(test_df.drop(columns=['label']))\n",
        "y_train = train_df['label'].astype(int)\n",
        "y_test = test_df['label'].astype(int)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
        "plot_class_distribution(y_balanced, 'Balanced Training Data', 'balanced_dist.png')\n",
        "\n",
        "# Cluster modeling\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_balanced)\n",
        "plot_clusters(X_balanced, clusters, 'clusters.png')\n",
        "\n",
        "# Train cluster models\n",
        "cluster_models = []\n",
        "train_scores = np.zeros(X_balanced.shape[0])\n",
        "\n",
        "for cluster in range(5):\n",
        "    cluster_data = X_balanced[clusters == cluster]\n",
        "    model = IsolationForest(\n",
        "        n_estimators=300,\n",
        "        max_samples='auto',\n",
        "        contamination=0.15,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    model.fit(cluster_data)\n",
        "    cluster_models.append(model)\n",
        "    train_scores[clusters == cluster] = -model.decision_function(cluster_data)\n",
        "\n",
        "# Generate test scores\n",
        "test_scores = np.zeros(X_test_scaled.shape[0])\n",
        "for model in cluster_models:\n",
        "    scores = -model.decision_function(X_test_scaled)\n",
        "    test_scores += scores\n",
        "test_scores /= len(cluster_models)\n",
        "\n",
        "# Visualization\n",
        "plot_anomaly_scores(test_scores, y_test, 'anomaly_scores.png')\n",
        "\n",
        "# Create enhanced features\n",
        "X_train_enhanced = np.hstack([X_balanced, train_scores.reshape(-1, 1)])\n",
        "X_test_enhanced = np.hstack([X_test_scaled, test_scores.reshape(-1, 1)])\n",
        "\n",
        "# Final model training\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=None,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train_enhanced, y_balanced)\n",
        "\n",
        "# Evaluation\n",
        "final_pred = rf_model.predict(X_test_enhanced)\n",
        "y_proba = rf_model.predict_proba(X_test_enhanced)[:, 1]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, final_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, final_pred):.2f}\")\n",
        "\n",
        "# Visual evaluation\n",
        "plot_feature_importance(rf_model, X_train.columns.tolist() + ['anomaly_score'])\n",
        "plot_confusion_matrix(y_test, final_pred, 'confusion_matrix.png')\n",
        "plot_roc_curve(y_test, y_proba, 'roc_curve.png')\n",
        "\n",
        "# Precision-Recall Curve\n",
        "plt.figure()\n",
        "PrecisionRecallDisplay.from_predictions(y_test, y_proba)\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.savefig('precision_recall.png', bbox_inches='tight')\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "snOb9oUtbzow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "27ef5cf2-5421-424d-dd0d-666f0fa82004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.93     56000\n",
            "           1       1.00      0.92      0.96    119341\n",
            "\n",
            "    accuracy                           0.95    175341\n",
            "   macro avg       0.93      0.96      0.94    175341\n",
            "weighted avg       0.96      0.95      0.95    175341\n",
            "\n",
            "Accuracy: 0.95\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIa7OWws6CDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRur4S32UID5MjBiIGBqqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}